{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMu3HeiJj6nKFsxam1sqfXV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d0036432371409887696387e9204962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41dcac0fbd0442afa20e1c88b151497a",
              "IPY_MODEL_ca584de6f366497ca218119bc3b342ea",
              "IPY_MODEL_dccccd6acefa43c78cddc2712ec611c9"
            ],
            "layout": "IPY_MODEL_2aec58221a1b4984b11313003b00ea63"
          }
        },
        "41dcac0fbd0442afa20e1c88b151497a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce6c33cf19b4465b944dec9aa7ba017",
            "placeholder": "​",
            "style": "IPY_MODEL_1b078eefbf70467aade32a9e61225ecc",
            "value": "config.json: 100%"
          }
        },
        "ca584de6f366497ca218119bc3b342ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fadde15b49ba447aad0b2fe2cdd58e9a",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_174da801aa4c456ba778fa541b4f0c16",
            "value": 684
          }
        },
        "dccccd6acefa43c78cddc2712ec611c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c4e7f7a76b1449ebd18a808c6ecda5d",
            "placeholder": "​",
            "style": "IPY_MODEL_25fd090831e54abbbf9a147397135456",
            "value": " 684/684 [00:00&lt;00:00, 58.5kB/s]"
          }
        },
        "2aec58221a1b4984b11313003b00ea63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce6c33cf19b4465b944dec9aa7ba017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b078eefbf70467aade32a9e61225ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fadde15b49ba447aad0b2fe2cdd58e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174da801aa4c456ba778fa541b4f0c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c4e7f7a76b1449ebd18a808c6ecda5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25fd090831e54abbbf9a147397135456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91cf649697774f7eb9c4e5b2b744b7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2621f22c6c7345eea9aa52f46abad91a",
              "IPY_MODEL_a7bf9341791543bfb75453d8d83fd044",
              "IPY_MODEL_9e39ed292e2b4c299e2bef418139c210"
            ],
            "layout": "IPY_MODEL_c5f743ade0b04baa95673d0e7303b94e"
          }
        },
        "2621f22c6c7345eea9aa52f46abad91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b83bfc1eda14a7ebf59302561357235",
            "placeholder": "​",
            "style": "IPY_MODEL_78c5d94325cb41419b57929e16d16194",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "a7bf9341791543bfb75453d8d83fd044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea250653b46e46d8ba0bbfd28fc97bd7",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88b8ed8555f64691b3a0c9a3c98bc5e0",
            "value": 23950
          }
        },
        "9e39ed292e2b4c299e2bef418139c210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cb2344e167b495b90ea3b627b8a28fa",
            "placeholder": "​",
            "style": "IPY_MODEL_ee33e6d29dc947b99594de145eba3734",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 2.00MB/s]"
          }
        },
        "c5f743ade0b04baa95673d0e7303b94e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b83bfc1eda14a7ebf59302561357235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c5d94325cb41419b57929e16d16194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea250653b46e46d8ba0bbfd28fc97bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b8ed8555f64691b3a0c9a3c98bc5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cb2344e167b495b90ea3b627b8a28fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee33e6d29dc947b99594de145eba3734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "930f8267ea02490780c43c2f2bf3c77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd37abc09a2c4f4f8bc7343fc417925a",
              "IPY_MODEL_5bc3b5a95b6f4034a283775bad8b10da",
              "IPY_MODEL_753958c8bc6e42f5945271b7b241acdf"
            ],
            "layout": "IPY_MODEL_749abb1fbf3649928d6a4ee3b07cc9b8"
          }
        },
        "cd37abc09a2c4f4f8bc7343fc417925a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55699df9d3d54513abb16aad30715624",
            "placeholder": "​",
            "style": "IPY_MODEL_6579d46193444748b90f9d91fad9c73b",
            "value": "Downloading shards:  33%"
          }
        },
        "5bc3b5a95b6f4034a283775bad8b10da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d978d7dccc364f87b8719d6d104d3a21",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5052ebca86544454ace37cc7f4cdfb32",
            "value": 1
          }
        },
        "753958c8bc6e42f5945271b7b241acdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bee20fdb442453d8cb3069d5e67c94f",
            "placeholder": "​",
            "style": "IPY_MODEL_660a86ac88d345f08b1a41753013d863",
            "value": " 1/3 [01:57&lt;03:54, 117.24s/it]"
          }
        },
        "749abb1fbf3649928d6a4ee3b07cc9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55699df9d3d54513abb16aad30715624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6579d46193444748b90f9d91fad9c73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d978d7dccc364f87b8719d6d104d3a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5052ebca86544454ace37cc7f4cdfb32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bee20fdb442453d8cb3069d5e67c94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660a86ac88d345f08b1a41753013d863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "725afe9bdb1d4395b32b389fdb52bb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76d9eaf2292248f7b665b30db6a9f284",
              "IPY_MODEL_84b93924cd9242ee913f45cc6ad7e3dd",
              "IPY_MODEL_cf5a09a2b571442f93ca081be3168972"
            ],
            "layout": "IPY_MODEL_08a5a76e1267489daab12e9618d9ddf9"
          }
        },
        "76d9eaf2292248f7b665b30db6a9f284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da78252aaee473ea5445e66aef3010c",
            "placeholder": "​",
            "style": "IPY_MODEL_c0814394ce0f4727b95ef695ba9e68d3",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "84b93924cd9242ee913f45cc6ad7e3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5da230901d3459db76b603de8953851",
            "max": 4915933984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8929690f8fc45b3834d1c878825dee1",
            "value": 4915933984
          }
        },
        "cf5a09a2b571442f93ca081be3168972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fc092695d5747d59a00894596f80d25",
            "placeholder": "​",
            "style": "IPY_MODEL_8e25268073c6466eb6b9683d03261748",
            "value": " 4.92G/4.92G [01:56&lt;00:00, 41.7MB/s]"
          }
        },
        "08a5a76e1267489daab12e9618d9ddf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da78252aaee473ea5445e66aef3010c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0814394ce0f4727b95ef695ba9e68d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5da230901d3459db76b603de8953851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8929690f8fc45b3834d1c878825dee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fc092695d5747d59a00894596f80d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e25268073c6466eb6b9683d03261748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fe3e72a6a5846adb20b4b84e3a77d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b62409d97983469fa0a209ce59fab07b",
              "IPY_MODEL_3b93e754e45c4474a83930ca427a1d51",
              "IPY_MODEL_8a786bc890b94681842c837cb4dcd9ed"
            ],
            "layout": "IPY_MODEL_7da954a30e0c4eb4a005e386e1a07958"
          }
        },
        "b62409d97983469fa0a209ce59fab07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e05957d913394a14a593f3887a287d83",
            "placeholder": "​",
            "style": "IPY_MODEL_7512a125f977444a9fbacdad2b6ded2f",
            "value": "model-00002-of-00003.safetensors:  34%"
          }
        },
        "3b93e754e45c4474a83930ca427a1d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b183303cfb84360b0ba4c57708a5707",
            "max": 4934842808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40244fd4e3a8478888ff44cc530b50e0",
            "value": 1667235840
          }
        },
        "8a786bc890b94681842c837cb4dcd9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62cbca15a6d04ee2a406c10323930479",
            "placeholder": "​",
            "style": "IPY_MODEL_9e3714d548ef4c6ea24bec428dc95288",
            "value": " 1.67G/4.93G [00:39&lt;01:16, 42.6MB/s]"
          }
        },
        "7da954a30e0c4eb4a005e386e1a07958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05957d913394a14a593f3887a287d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7512a125f977444a9fbacdad2b6ded2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b183303cfb84360b0ba4c57708a5707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40244fd4e3a8478888ff44cc530b50e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62cbca15a6d04ee2a406c10323930479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e3714d548ef4c6ea24bec428dc95288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezabonyadi/YuE/blob/main/YuE_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t9_t3YWU0R-5",
        "outputId": "b6460daa-171c-4c89-b105-82b3d6a0ef15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Git LFS initialized.\n",
            "Cloning into 'YuE'...\n",
            "remote: Enumerating objects: 369, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 369 (delta 101), reused 88 (delta 88), pack-reused 262 (from 1)\u001b[K\n",
            "Receiving objects: 100% (369/369), 12.99 MiB | 17.26 MiB/s, done.\n",
            "Resolving deltas: 100% (160/160), done.\n",
            "/content/YuE/inference\n",
            "Cloning into 'xcodec_mini_infer'...\n",
            "remote: Enumerating objects: 203, done.\u001b[K\n",
            "remote: Counting objects: 100% (199/199), done.\u001b[K\n",
            "remote: Compressing objects: 100% (186/186), done.\u001b[K\n",
            "remote: Total 203 (delta 8), reused 199 (delta 8), pack-reused 4 (from 1)\u001b[K\n",
            "Receiving objects: 100% (203/203), 8.38 MiB | 9.36 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "Filtering content: 100% (4/4), 1.75 GiB | 49.39 MiB/s, done.\n",
            "/content/YuE\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Collecting omegaconf (from -r requirements.txt (line 2))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.47.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.18.0)\n",
            "Collecting descript-audiotools>=0.7.2 (from -r requirements.txt (line 10))\n",
            "  Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting descript-audio-codec (from -r requirements.txt (line 11))\n",
            "  Downloading descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting scipy==1.10.1 (from -r requirements.txt (line 12))\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 2))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 6)) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 6)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 6)) (0.5.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.1.3)\n",
            "Collecting argbind (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading argbind-0.3.9.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.13.1)\n",
            "Collecting pyloudnorm (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (6.5.2)\n",
            "Collecting julius (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpy (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (7.34.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (13.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.10.2.post1)\n",
            "Collecting pystoi (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting torch-stoi (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flatten-dict (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting markdown2 (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting randomname (from descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading randomname-0.2.1.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r requirements.txt (line 9))\n",
            "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->-r requirements.txt (line 13)) (5.9.5)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.11/dist-packages (from argbind->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 9)) (3.0.2)\n",
            "Collecting jedi>=0.16 (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (4.9.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.17.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from pyloudnorm->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (1.0.0)\n",
            "Collecting fire (from randomname->descript-audiotools>=0.7.2->-r requirements.txt (line 10))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 6)) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.43.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (4.3.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (0.2.13)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->randomname->descript-audiotools>=0.7.2->-r requirements.txt (line 10)) (2.5.0)\n",
            "Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Downloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, argbind, julius, randomname, fire\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=ff258160367871a3cc64c60422c6cfecb43de383ca351429a3c97e0b77082e7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for argbind (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for argbind: filename=argbind-0.3.9-py2.py3-none-any.whl size=11729 sha256=a5c65930f938ce26c51d64c8eeec67c8925a90137bf3b56af678e080229c77f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/3a/34/e858fa3cf5f8c33a040734efcc17e95cb5cfd99c256a7fcecf\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=767d9cf2cb46192d3229ea846a3be58b4225941c1e7163d6c690c8e3841d3939\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for randomname: filename=randomname-0.2.1-py3-none-any.whl size=89195 sha256=442fda6ae438edfb1e961c0f6f5374e861aa1dd9e36087a228f0788dce60f1fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/b3/ae/c137ed34d7c385b74ae440b4f008183264ebe466ea0341db09\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=3052cef9baf4e8d98f21cae9ba3e7a10363dd20661db2d8de22716378102993f\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built antlr4-python3-runtime argbind julius randomname fire\n",
            "Installing collected packages: antlr4-python3-runtime, scipy, protobuf, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markdown2, jedi, flatten-dict, fire, ffmpy, argbind, randomname, pystoi, pyloudnorm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, julius, torch-stoi, descript-audiotools, descript-audio-codec\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.1 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.28.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.7 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-spanner 3.51.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 argbind-0.3.9 descript-audio-codec-1.0.0 descript-audiotools-0.7.2 ffmpy-0.5.0 fire-0.7.0 flatten-dict-0.4.2 jedi-0.19.2 julius-0.2.7 markdown2-2.5.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 protobuf-3.19.6 pyloudnorm-0.1.1 pystoi-0.4.1 randomname-0.2.1 scipy-1.10.1 torch-stoi-0.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pydevd_plugins"
                ]
              },
              "id": "4a740c60f5a64c9ab1aa2cc65ad4c9ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'YuE/inference'\n",
            "/content/YuE\n"
          ]
        }
      ],
      "source": [
        "# Install Git LFS (if not already installed)\n",
        "!apt-get install git-lfs -y\n",
        "!git lfs install\n",
        "\n",
        "# Clone the main YuE repository\n",
        "!git clone https://github.com/multimodal-art-projection/YuE.git\n",
        "\n",
        "# Navigate into the inference directory and clone the xcodec_mini_infer repo\n",
        "%cd YuE/inference\n",
        "!git clone https://huggingface.co/m-a-p/xcodec_mini_infer\n",
        "%cd ..\n",
        "!pip install -r requirements.txt\n",
        "%cd YuE/inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch=='2.4.1+cu121' torchvision=='0.19.1+cu121' torchaudio=='2.4.1+cu121' --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install flash-attn\n",
        "!pip install protobuf==3.20.1 # This is to fix the version problem of the one from YuE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9xFgE3yw-HvX",
        "outputId": "d33555a2-ceff-4277-ef51-e03dcd89beb2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.1+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.1+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.1+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1+cu121) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1+cu121) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1+cu121) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1+cu121) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1+cu121) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1+cu121) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1+cu121) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.1+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1+cu121) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1+cu121) (11.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1+cu121) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1+cu121) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1+cu121) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu124\n",
            "    Uninstalling torchaudio-2.5.1+cu124:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.4.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187805408 sha256=92cf49e6f66795b6934cec0cba526ed6e45d3313de3f905d45df8773f19092a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n",
            "Collecting protobuf==3.20.1\n",
            "  Downloading protobuf-3.20.1-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.1-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "descript-audiotools 0.7.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigtable 2.28.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.19.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-spanner 3.51.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-pubsub 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "f701d7e5532c46a28650e66436b2fbad"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB0Vqv6w-vXf",
        "outputId": "8362ba0a-0c45-442e-baff-7f48825a87ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  YuE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd YuE/inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUUEaziK32S2",
        "outputId": "a5fc02b5-60f1-4002-d54d-2a696fb2c9f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YuE/inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Use the current working directory instead of __file__\n",
        "base_path = os.getcwd()\n",
        "sys.path.append(os.path.join(base_path, 'xcodec_mini_infer'))\n",
        "sys.path.append(os.path.join(base_path, 'xcodec_mini_infer', 'descriptaudiocodec'))\n",
        "\n",
        "import argparse\n",
        "\n",
        "# Create a dummy args object with at least the required attributes.\n",
        "dummy_args = argparse.Namespace(bw=4, cuda_idx=0)\n",
        "\n",
        "import re\n",
        "import random\n",
        "import uuid\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample\n",
        "import soundfile as sf\n",
        "from einops import rearrange\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessor, LogitsProcessorList\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "from codecmanipulator import CodecManipulator\n",
        "from mmtokenizer import _MMSentencePieceTokenizer\n",
        "from models.soundstream_hubert_new import SoundStream\n",
        "from vocoder import build_codec_model, process_audio\n",
        "from post_process_audio import replace_low_freq_with_energy_matched\n",
        "\n",
        "\n",
        "class BlockTokenRangeProcessor(LogitsProcessor):\n",
        "    def __init__(self, start_id, end_id):\n",
        "        self.blocked_token_ids = list(range(start_id, end_id))\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        scores[:, self.blocked_token_ids] = -float(\"inf\")\n",
        "        return scores\n",
        "\n",
        "# Set random seed\n",
        "def seed_everything(seed_val=42):\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Audio utilities\n",
        "def load_audio_mono(filepath, sampling_rate=16000):\n",
        "    audio, sr = torchaudio.load(filepath)\n",
        "    audio = torch.mean(audio, dim=0, keepdim=True)\n",
        "    if sr != sampling_rate:\n",
        "        resampler = Resample(orig_freq=sr, new_freq=sampling_rate)\n",
        "        audio = resampler(audio)\n",
        "    return audio\n",
        "\n",
        "def encode_audio(codec_model, audio_prompt, device, target_bw=0.5):\n",
        "    if len(audio_prompt.shape) < 3:\n",
        "        audio_prompt = audio_prompt.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        raw_codes = codec_model.encode(audio_prompt.to(device), target_bw=target_bw)\n",
        "    raw_codes = raw_codes.transpose(0, 1)\n",
        "    raw_codes = raw_codes.cpu().numpy().astype(np.int16)\n",
        "    return raw_codes\n",
        "\n",
        "def split_lyrics(lyrics_content):\n",
        "    pattern = r\"\\[(\\w+)\\](.*?)\\n(?=\\[|\\Z)\"\n",
        "    segments = re.findall(pattern, lyrics_content, re.DOTALL)\n",
        "    structured_lyrics = [f\"[{seg[0]}]\\n{seg[1].strip()}\\n\\n\" for seg in segments]\n",
        "    return structured_lyrics\n",
        "\n",
        "def stage2_generate(model, prompt, batch_size=16):\n",
        "    codec_ids = codectool.unflatten(prompt, n_quantizer=1)\n",
        "    codec_ids = codectool.offset_tok_ids(\n",
        "        codec_ids,\n",
        "        global_offset=codectool.global_offset,\n",
        "        codebook_size=codectool.codebook_size,\n",
        "        num_codebooks=codectool.num_codebooks,\n",
        "    ).astype(np.int32)\n",
        "\n",
        "    if batch_size > 1:\n",
        "        codec_list = []\n",
        "        for i in range(batch_size):\n",
        "            idx_begin = i * 300\n",
        "            idx_end = (i + 1) * 300\n",
        "            codec_list.append(codec_ids[:, idx_begin:idx_end])\n",
        "        codec_ids = np.concatenate(codec_list, axis=0)\n",
        "        prompt_ids = np.concatenate(\n",
        "            [\n",
        "                np.tile([mmtokenizer.soa, mmtokenizer.stage_1], (batch_size, 1)),\n",
        "                codec_ids,\n",
        "                np.tile([mmtokenizer.stage_2], (batch_size, 1)),\n",
        "            ],\n",
        "            axis=1\n",
        "        )\n",
        "    else:\n",
        "        prompt_ids = np.concatenate([\n",
        "            np.array([mmtokenizer.soa, mmtokenizer.stage_1]),\n",
        "            codec_ids.flatten(),\n",
        "            np.array([mmtokenizer.stage_2])\n",
        "        ]).astype(np.int32)\n",
        "        prompt_ids = prompt_ids[np.newaxis, ...]\n",
        "    codec_ids = torch.as_tensor(codec_ids).to(device)\n",
        "    prompt_ids = torch.as_tensor(prompt_ids).to(device)\n",
        "    len_prompt = prompt_ids.shape[-1]\n",
        "    block_list = LogitsProcessorList([\n",
        "        BlockTokenRangeProcessor(0, 46358),\n",
        "        BlockTokenRangeProcessor(53526, mmtokenizer.vocab_size)\n",
        "    ])\n",
        "\n",
        "    for frames_idx in range(codec_ids.shape[1]):\n",
        "        cb0 = codec_ids[:, frames_idx:frames_idx+1]\n",
        "        prompt_ids = torch.cat([prompt_ids, cb0], dim=1)\n",
        "        input_ids = prompt_ids\n",
        "        with torch.no_grad():\n",
        "            stage2_output = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                min_new_tokens=7,\n",
        "                max_new_tokens=7,\n",
        "                eos_token_id=mmtokenizer.eoa,\n",
        "                pad_token_id=mmtokenizer.eoa,\n",
        "                logits_processor=block_list,\n",
        "            )\n",
        "        assert stage2_output.shape[1] - prompt_ids.shape[1] == 7, \\\n",
        "            f\"output new tokens={stage2_output.shape[1]-prompt_ids.shape[1]}\"\n",
        "        prompt_ids = stage2_output\n",
        "\n",
        "    if batch_size > 1:\n",
        "        output = prompt_ids.cpu().numpy()[:, len_prompt:]\n",
        "        output_list = [output[i] for i in range(batch_size)]\n",
        "        output = np.concatenate(output_list, axis=0)\n",
        "    else:\n",
        "        output = prompt_ids[0].cpu().numpy()[len_prompt:]\n",
        "    return output\n",
        "\n",
        "def stage2_inference(model, stage1_output_set, stage2_output_dir, batch_size=4):\n",
        "    stage2_result = []\n",
        "    codectool_stage2 = CodecManipulator(\"xcodec\", 0, 8)\n",
        "    for file_path in tqdm(stage1_output_set):\n",
        "        output_filename = os.path.join(stage2_output_dir, os.path.basename(file_path))\n",
        "        if os.path.exists(output_filename):\n",
        "            print(f'{output_filename} stage2 has done.')\n",
        "            stage2_result.append(output_filename)\n",
        "            continue\n",
        "        prompt = np.load(file_path).astype(np.int32)\n",
        "        output_duration = prompt.shape[-1] // 50 // 6 * 6\n",
        "        num_batch = output_duration // 6\n",
        "        if num_batch <= batch_size:\n",
        "            output = stage2_generate(model, prompt[:, :output_duration * 50], batch_size=num_batch)\n",
        "        else:\n",
        "            segments = []\n",
        "            num_segments = (num_batch // batch_size) + (1 if num_batch % batch_size != 0 else 0)\n",
        "            for seg in range(num_segments):\n",
        "                start_idx = seg * batch_size * 300\n",
        "                end_idx = min((seg + 1) * batch_size * 300, output_duration * 50)\n",
        "                current_batch_size = batch_size if (seg != num_segments-1 or num_batch % batch_size == 0) else num_batch % batch_size\n",
        "                segment = stage2_generate(model, prompt[:, start_idx:end_idx], batch_size=current_batch_size)\n",
        "                segments.append(segment)\n",
        "            output = np.concatenate(segments, axis=0)\n",
        "        if output_duration * 50 != prompt.shape[-1]:\n",
        "            ending = stage2_generate(model, prompt[:, output_duration * 50:], batch_size=1)\n",
        "            output = np.concatenate([output, ending], axis=0)\n",
        "        output = codectool_stage2.ids2npy(output)\n",
        "        fixed_output = copy.deepcopy(output)\n",
        "        for i, line in enumerate(output):\n",
        "            for j, element in enumerate(line):\n",
        "                if element < 0 or element > 1023:\n",
        "                    counter = Counter(line)\n",
        "                    most_frequent = sorted(counter.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
        "                    fixed_output[i, j] = most_frequent\n",
        "        np.save(output_filename, fixed_output)\n",
        "        stage2_result.append(output_filename)\n",
        "    return stage2_result\n",
        "\n",
        "# Helper to save audio files\n",
        "def save_audio(wav: torch.Tensor, path, sample_rate: int, rescale_flag: bool = False):\n",
        "    folder_path = os.path.dirname(path)\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "    limit = 0.99\n",
        "    max_val = wav.abs().max()\n",
        "    wav = wav * min(limit / max_val, 1) if rescale_flag else wav.clamp(-limit, limit)\n",
        "    torchaudio.save(str(path), wav, sample_rate=sample_rate, encoding='PCM_S', bits_per_sample=16)\n"
      ],
      "metadata": {
        "id": "uudTGVdU0Ucx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import uuid\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "# Assume these functions/classes are imported or defined elsewhere:\n",
        "#   - _MMSentencePieceTokenizer, AutoModelForCausalLM, CodecManipulator,\n",
        "#   - seed_everything, split_lyrics, load_audio_mono, encode_audio,\n",
        "#   - LogitsProcessorList, BlockTokenRangeProcessor, stage2_inference,\n",
        "#   - save_audio, build_codec_model, process_audio, replace_low_freq_with_energy_matched\n",
        "\n",
        "def validate_prompt_options(use_audio_prompt, audio_prompt_path,\n",
        "                            use_dual_tracks_prompt, vocal_track_prompt_path, instrumental_track_prompt_path):\n",
        "    \"\"\"Validate that if prompts are enabled, file paths are provided.\"\"\"\n",
        "    if use_audio_prompt and not audio_prompt_path:\n",
        "        raise FileNotFoundError(\"Audio prompt is enabled but no audio_prompt_path was provided!\")\n",
        "    if use_dual_tracks_prompt and (not vocal_track_prompt_path or not instrumental_track_prompt_path):\n",
        "        raise FileNotFoundError(\"Dual tracks prompt is enabled but vocal_track_prompt_path and instrumental_track_prompt_path are not provided!\")\n",
        "\n",
        "def setup_output_directories(output_dir):\n",
        "    \"\"\"Set up and return directories for each pipeline stage.\"\"\"\n",
        "    stage1_output_dir = os.path.join(output_dir, \"stage1\")\n",
        "    stage2_output_dir = stage1_output_dir.replace('stage1', 'stage2')\n",
        "    recons_output_dir = os.path.join(output_dir, \"recons\")\n",
        "    recons_mix_dir = os.path.join(recons_output_dir, 'mix')\n",
        "    os.makedirs(stage1_output_dir, exist_ok=True)\n",
        "    os.makedirs(stage2_output_dir, exist_ok=True)\n",
        "    os.makedirs(recons_mix_dir, exist_ok=True)\n",
        "    return stage1_output_dir, stage2_output_dir, recons_output_dir, recons_mix_dir\n",
        "\n",
        "def load_stage1_model(stage1_model, device):\n",
        "    \"\"\"Load and compile the Stage 1 model.\"\"\"\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        stage1_model,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        attn_implementation=\"flash_attention_2\"  # Note: may not work well on Colab\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    if torch.__version__ >= \"2.0.0\":\n",
        "        model = torch.compile(model)\n",
        "    return model\n",
        "\n",
        "def load_codec_model(basic_model_config, resume_path, device):\n",
        "    \"\"\"Load the codec model used for encoding/decoding audio.\"\"\"\n",
        "    model_config = OmegaConf.load(basic_model_config)\n",
        "    codec_model = eval(model_config.generator.name)(**model_config.generator.config).to(device)\n",
        "    parameter_dict = torch.load(resume_path, map_location='cpu', weights_only=False)\n",
        "    codec_model.load_state_dict(parameter_dict['codec_model'])\n",
        "    codec_model.to(device)\n",
        "    codec_model.eval()\n",
        "    return codec_model\n",
        "\n",
        "def read_prompt_files(genre_txt, lyrics_txt):\n",
        "    \"\"\"Read the genre and lyrics prompt files and build the prompt texts.\"\"\"\n",
        "    with open(genre_txt, \"r\") as f:\n",
        "        genres = f.read().strip()\n",
        "    with open(lyrics_txt, \"r\") as f:\n",
        "        lyrics_content = f.read()\n",
        "    lyrics = split_lyrics(lyrics_content)\n",
        "    full_lyrics = \"\\n\".join(lyrics)\n",
        "    # The first prompt is a full description; subsequent ones are segment-specific.\n",
        "    prompt_texts = [f\"Generate music from the given lyrics segment by segment.\\n[Genre] {genres}\\n{full_lyrics}\"]\n",
        "    prompt_texts += lyrics\n",
        "    return genres, prompt_texts\n",
        "\n",
        "def generate_stage1_outputs(prompt_texts, genres, model, mmtokenizer, codectool, codec_model, device,\n",
        "                             use_audio_prompt, audio_prompt_path, use_dual_tracks_prompt,\n",
        "                             vocal_track_prompt_path, instrumental_track_prompt_path,\n",
        "                             prompt_start_time, prompt_end_time, max_new_tokens,\n",
        "                             top_p, temperature, repetition_penalty, stage1_output_dir):\n",
        "    \"\"\"\n",
        "    Process each prompt segment and generate Stage 1 outputs.\n",
        "    This function builds the prompt tokens (handling audio/dual-track if enabled),\n",
        "    runs generation, and then saves the raw output tokens into files.\n",
        "    \"\"\"\n",
        "    raw_output = None\n",
        "    stage1_output_set = []\n",
        "    random_id = uuid.uuid4()\n",
        "\n",
        "    # Here we assume the first prompt (index 0) is the head (full prompt)\n",
        "    # and subsequent segments are generated one by one.\n",
        "    run_n_segments = min(len(prompt_texts), len(prompt_texts))  # Adjust if needed\n",
        "    for i, p in enumerate(tqdm(prompt_texts[:run_n_segments])):\n",
        "        section_text = p.replace('[start_of_segment]', '').replace('[end_of_segment]', '')\n",
        "        guidance_scale = 1.5 if i <= 1 else 1.2\n",
        "\n",
        "        # Skip the first prompt for generation (or handle it as needed)\n",
        "        if i == 0:\n",
        "            continue\n",
        "\n",
        "        # Build prompt tokens with optional audio/dual-track inputs\n",
        "        if i == 1:\n",
        "            if use_dual_tracks_prompt or use_audio_prompt:\n",
        "                if use_dual_tracks_prompt:\n",
        "                    vocals_ids = load_audio_mono(vocal_track_prompt_path)\n",
        "                    instrumental_ids = load_audio_mono(instrumental_track_prompt_path)\n",
        "                    vocals_ids = encode_audio(codec_model, vocals_ids, device, target_bw=0.5)\n",
        "                    instrumental_ids = encode_audio(codec_model, instrumental_ids, device, target_bw=0.5)\n",
        "                    vocals_ids = codectool.npy2ids(vocals_ids[0])\n",
        "                    instrumental_ids = codectool.npy2ids(instrumental_ids[0])\n",
        "                    # Interleave the two tracks\n",
        "                    ids_segment_interleaved = np.concatenate([np.array(vocals_ids), np.array(instrumental_ids)], axis=0)\n",
        "                    audio_prompt_codec = ids_segment_interleaved[int(prompt_start_time * 50 * 2): int(prompt_end_time * 50 * 2)]\n",
        "                    audio_prompt_codec = audio_prompt_codec.tolist()\n",
        "                elif use_audio_prompt:\n",
        "                    audio_prompt = load_audio_mono(audio_prompt_path)\n",
        "                    raw_codes = encode_audio(codec_model, audio_prompt, device, target_bw=0.5)\n",
        "                    code_ids = codectool.npy2ids(raw_codes[0])\n",
        "                    audio_prompt_codec = code_ids[int(prompt_start_time * 50): int(prompt_end_time * 50)]\n",
        "                audio_prompt_codec_ids = [mmtokenizer.soa] + codectool.sep_ids + audio_prompt_codec + [mmtokenizer.eoa]\n",
        "                sentence_ids = (mmtokenizer.tokenize(\"[start_of_reference]\") +\n",
        "                                audio_prompt_codec_ids +\n",
        "                                mmtokenizer.tokenize(\"[end_of_reference]\"))\n",
        "                head_id = mmtokenizer.tokenize(prompt_texts[0]) + sentence_ids\n",
        "            else:\n",
        "                head_id = mmtokenizer.tokenize(prompt_texts[0])\n",
        "            prompt_ids = (head_id +\n",
        "                          mmtokenizer.tokenize('[start_of_segment]') +\n",
        "                          mmtokenizer.tokenize(section_text) +\n",
        "                          [mmtokenizer.soa] + codectool.sep_ids)\n",
        "        else:\n",
        "            prompt_ids = (mmtokenizer.tokenize('[end_of_segment]') +\n",
        "                          mmtokenizer.tokenize('[start_of_segment]') +\n",
        "                          mmtokenizer.tokenize(section_text) +\n",
        "                          [mmtokenizer.soa] + codectool.sep_ids)\n",
        "\n",
        "        prompt_ids = torch.as_tensor(prompt_ids).unsqueeze(0).to(device)\n",
        "        # Concatenate with previous outputs if not the first generation segment\n",
        "        input_ids = torch.cat([raw_output, prompt_ids], dim=1) if raw_output is not None else prompt_ids\n",
        "\n",
        "        # Trim input if it exceeds the model context window\n",
        "        max_context = 16384 - max_new_tokens - 1\n",
        "        if input_ids.shape[-1] > max_context:\n",
        "            print(f'Section {i}: input length {input_ids.shape[-1]} exceeds max context {max_context}, using last tokens.')\n",
        "            input_ids = input_ids[:, -max_context:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_seq = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                min_new_tokens=100,\n",
        "                do_sample=True,\n",
        "                top_p=top_p,\n",
        "                temperature=temperature,\n",
        "                repetition_penalty=repetition_penalty,\n",
        "                eos_token_id=mmtokenizer.eoa,\n",
        "                pad_token_id=mmtokenizer.eoa,\n",
        "                logits_processor=LogitsProcessorList([\n",
        "                    BlockTokenRangeProcessor(0, 32002),\n",
        "                    BlockTokenRangeProcessor(32016, 32016)\n",
        "                ]),\n",
        "                guidance_scale=guidance_scale,\n",
        "            )\n",
        "            # Append eos token if missing\n",
        "            if output_seq[0][-1].item() != mmtokenizer.eoa:\n",
        "                tensor_eoa = torch.as_tensor([[mmtokenizer.eoa]]).to(model.device)\n",
        "                output_seq = torch.cat((output_seq, tensor_eoa), dim=1)\n",
        "\n",
        "        # Accumulate raw output for subsequent segments\n",
        "        if raw_output is not None:\n",
        "            raw_output = torch.cat([raw_output, prompt_ids, output_seq[:, input_ids.shape[-1]:]], dim=1)\n",
        "        else:\n",
        "            raw_output = output_seq\n",
        "\n",
        "    # Save the final raw output tokens as separate npy files for vocals and instrumentals\n",
        "    ids = raw_output[0].cpu().numpy()\n",
        "    soa_idx = np.where(ids == mmtokenizer.soa)[0].tolist()\n",
        "    eoa_idx = np.where(ids == mmtokenizer.eoa)[0].tolist()\n",
        "    if len(soa_idx) != len(eoa_idx):\n",
        "        raise ValueError(f'Invalid pairs of soa and eoa, Num of soa: {len(soa_idx)}, Num of eoa: {len(eoa_idx)}')\n",
        "\n",
        "    vocals = []\n",
        "    instrumentals = []\n",
        "    # Adjust range based on whether an audio prompt was used\n",
        "    range_begin = 1 if (use_audio_prompt or use_dual_tracks_prompt) else 0\n",
        "    for i in range(range_begin, len(soa_idx)):\n",
        "        codec_ids = ids[soa_idx[i] + 1:eoa_idx[i]]\n",
        "        if codec_ids[0] == 32016:\n",
        "            codec_ids = codec_ids[1:]\n",
        "        # Ensure even number of tokens to split into two channels\n",
        "        codec_ids = codec_ids[:2 * (len(codec_ids) // 2)]\n",
        "        # Reshape assuming vocals and instrumentals are interleaved\n",
        "        reshaped = np.reshape(codec_ids, (-1, 2))\n",
        "        vocals_ids = codectool.ids2npy(reshaped[:, 0])\n",
        "        instrumentals_ids = codectool.ids2npy(reshaped[:, 1])\n",
        "        vocals.append(vocals_ids)\n",
        "        instrumentals.append(instrumentals_ids)\n",
        "    vocals = np.concatenate(vocals, axis=1)\n",
        "    instrumentals = np.concatenate(instrumentals, axis=1)\n",
        "\n",
        "    vocal_save_path = os.path.join(\n",
        "        stage1_output_dir,\n",
        "        f\"{genres.replace(' ', '-')}_vtrack_{random_id}.npy\"\n",
        "    )\n",
        "    inst_save_path = os.path.join(\n",
        "        stage1_output_dir,\n",
        "        f\"{genres.replace(' ', '-')}_itrack_{random_id}.npy\"\n",
        "    )\n",
        "    # Save npy files accordingly.\n",
        "    np.save(vocal_save_path, vocals)\n",
        "    np.save(inst_save_path, instrumentals)\n",
        "\n",
        "    # vocal_save_path = os.path.join(\n",
        "    #     os.path.dirname(stage1_output_set[0]) if stage1_output_set else \".\",\n",
        "    #     f\"{genres.replace(' ', '-')}_vtrack_{random_id}.npy\"\n",
        "    # )\n",
        "    # inst_save_path = os.path.join(\n",
        "    #     os.path.dirname(stage1_output_set[0]) if stage1_output_set else \".\",\n",
        "    #     f\"{genres.replace(' ', '-')}_itrack_{random_id}.npy\"\n",
        "    # )\n",
        "    # np.save(vocal_save_path, vocals)\n",
        "    # np.save(inst_save_path, instrumentals)\n",
        "    stage1_output_set.extend([vocal_save_path, inst_save_path])\n",
        "    return stage1_output_set\n",
        "\n",
        "def run_stage2_inference(stage2_model, stage1_output_set, stage2_output_dir, stage2_batch_size, device):\n",
        "    \"\"\"Load and run Stage 2 model on the outputs from Stage 1.\"\"\"\n",
        "    model_stage2 = AutoModelForCausalLM.from_pretrained(\n",
        "        stage2_model,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        attn_implementation=\"flash_attention_2\",\n",
        "    )\n",
        "    model_stage2.to(device)\n",
        "    model_stage2.eval()\n",
        "    if torch.__version__ >= \"2.0.0\":\n",
        "        model_stage2 = torch.compile(model_stage2)\n",
        "    stage2_result = stage2_inference(model_stage2, stage1_output_set, stage2_output_dir, batch_size=stage2_batch_size)\n",
        "    print(\"Stage 2 outputs:\", stage2_result)\n",
        "    return stage2_result\n",
        "\n",
        "def reconstruct_tracks(stage2_result, stage1_output_dir, codec_model, device):\n",
        "    \"\"\"Decode the stage 2 npy files into audio tracks and save them.\"\"\"\n",
        "    tracks = []\n",
        "    for npy_file in stage2_result:\n",
        "        codec_result = np.load(npy_file)\n",
        "        with torch.no_grad():\n",
        "            decoded_waveform = codec_model.decode(\n",
        "                torch.as_tensor(codec_result.astype(np.int16), dtype=torch.long)\n",
        "                .unsqueeze(0).permute(1, 0, 2).to(device)\n",
        "            )\n",
        "        decoded_waveform = decoded_waveform.cpu().squeeze(0)\n",
        "        save_path = os.path.join(stage1_output_dir,\n",
        "                                 os.path.splitext(os.path.basename(npy_file))[0] + \".mp3\")\n",
        "        tracks.append(save_path)\n",
        "        save_audio(decoded_waveform, save_path, 16000)\n",
        "    return tracks\n",
        "\n",
        "def mix_tracks(tracks, recons_mix_dir):\n",
        "    \"\"\"Mix vocal and instrumental tracks into a single audio file.\"\"\"\n",
        "    recons_mix = None\n",
        "    for inst_path in tracks:\n",
        "        try:\n",
        "            if (inst_path.endswith('.wav') or inst_path.endswith('.mp3')) and '_itrack' in inst_path:\n",
        "                vocal_path = inst_path.replace('_itrack', '_vtrack')\n",
        "                if not os.path.exists(vocal_path):\n",
        "                    continue\n",
        "                recons_mix = os.path.join(recons_mix_dir, os.path.basename(inst_path).replace('_itrack', '_mixed'))\n",
        "                vocal_stem, sr = sf.read(inst_path)\n",
        "                instrumental_stem, _ = sf.read(vocal_path)\n",
        "                mix_stem = (vocal_stem + instrumental_stem) / 1\n",
        "                sf.write(recons_mix, mix_stem, sr)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    return recons_mix\n",
        "\n",
        "def upsample_vocoder(stage2_result, codec_model, config_path, vocal_decoder_path, inst_decoder_path, output_dir, rescale):\n",
        "    \"\"\"Perform vocoder upsampling using decoder models to produce high-quality audio.\"\"\"\n",
        "    vocal_decoder, inst_decoder = build_codec_model(config_path, vocal_decoder_path, inst_decoder_path)\n",
        "    vocoder_output_dir = os.path.join(output_dir, 'vocoder')\n",
        "    vocoder_stems_dir = os.path.join(vocoder_output_dir, 'stems')\n",
        "    vocoder_mix_dir = os.path.join(vocoder_output_dir, 'mix')\n",
        "    os.makedirs(vocoder_mix_dir, exist_ok=True)\n",
        "    os.makedirs(vocoder_stems_dir, exist_ok=True)\n",
        "    vocal_output = None\n",
        "    instrumental_output = None\n",
        "\n",
        "    for npy_file in stage2_result:\n",
        "        if '_itrack' in npy_file:\n",
        "            instrumental_output = process_audio(\n",
        "                npy_file,\n",
        "                os.path.join(vocoder_stems_dir, 'itrack.mp3'),\n",
        "                rescale,\n",
        "                dummy_args,\n",
        "                inst_decoder,\n",
        "                codec_model\n",
        "            )\n",
        "        else:\n",
        "            vocal_output = process_audio(\n",
        "                npy_file,\n",
        "                os.path.join(vocoder_stems_dir, 'vtrack.mp3'),\n",
        "                rescale,\n",
        "                dummy_args,\n",
        "                vocal_decoder,\n",
        "                codec_model\n",
        "            )\n",
        "    try:\n",
        "        mix_output = instrumental_output + vocal_output\n",
        "        vocoder_mix = os.path.join(vocoder_mix_dir, 'mixed_output.mp3')\n",
        "        save_audio(mix_output, vocoder_mix, 44100, rescale)\n",
        "        print(f\"Created mix: {vocoder_mix}\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "        print(f\"Mixing failed! instrumental shape: {instrumental_output.shape}, vocal shape: {vocal_output.shape}\")\n",
        "        vocoder_mix = None\n",
        "    return vocoder_mix\n",
        "\n",
        "def post_process_audio(recons_mix, vocoder_mix, output_dir):\n",
        "    \"\"\"Blend low frequencies from the reconstructed and vocoder outputs.\"\"\"\n",
        "    final_mix_path = os.path.join(output_dir, os.path.basename(recons_mix))\n",
        "    replace_low_freq_with_energy_matched(\n",
        "        a_file=recons_mix,     # 16kHz file\n",
        "        b_file=vocoder_mix,    # 48kHz file\n",
        "        c_file=final_mix_path,\n",
        "        cutoff_freq=5500.0\n",
        "    )\n",
        "    print(\"Post processing complete.\")\n",
        "    return final_mix_path\n"
      ],
      "metadata": {
        "id": "7oqVoUBo5qmF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyric = \"\"\"\n",
        "[Verse 1]\n",
        "A new dawn is rising, sparks ignite the sky\n",
        "Dreams once locked in pages, now they come alive\n",
        "We're painting with data, a vision so bright\n",
        "Turning the unknown into clear insight\n",
        "\n",
        "[Chorus]\n",
        "Every code we write, pushing past the line\n",
        "Every thought we chase, breaking space and time\n",
        "You can't stop the future now\n",
        "We won't slow down\n",
        "The world is changing, hear the sound\n",
        "We won't slow down\n",
        "\n",
        "[Verse 2]\n",
        "They say it's just machines, but they don't understand\n",
        "Behind the circuits, there's a guiding hand\n",
        "We see the unseen, weave logic and light\n",
        "Expanding the world with a keystroke at night\n",
        "\n",
        "[Chorus]\n",
        "Every code we write, pushing past the line\n",
        "Every thought we chase, breaking space and time\n",
        "You can't stop the future now\n",
        "We won't slow down\n",
        "The world is changing, hear the sound\n",
        "We won't slow down\n",
        "\n",
        "[Bridge]\n",
        "Imagination unbound, the limits erased\n",
        "A symphony of learning, the patterns embraced\n",
        "From vision to motion, from whispers to speech\n",
        "The edge of tomorrow is right within reach\n",
        "\n",
        "[Outro]\n",
        "Every dream we chase, rewriting the rules\n",
        "A world built on knowledge, breaking through\n",
        "You can't stop the future now\n",
        "We won't slow down\n",
        "With AI rising all around\n",
        "We won’t slow down\n",
        "\"\"\"\n",
        "\n",
        "with open('../prompt_egs/lyrics_AI.txt', 'w') as f:\n",
        "    f.write(lyric)"
      ],
      "metadata": {
        "id": "q_-OfbdZpg_V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_txt=\"../prompt_egs/genre.txt\"\n",
        "lyrics_txt=\"../prompt_egs/lyrics_AI.txt\"\n",
        "use_audio_prompt=False         # or True if using an audio prompt\n",
        "use_dual_tracks_prompt=False     # or True if using dual tracks\n",
        "output_dir=\"./my_output\"\n",
        "# Adjust other parameters as needed…\n",
        "\n",
        "\n",
        "# Model and generation configuration\n",
        "stage1_model = \"m-a-p/YuE-s1-7B-anneal-en-cot\"\n",
        "stage2_model = \"m-a-p/YuE-s2-1B-general\"\n",
        "max_new_tokens = 3000\n",
        "run_n_segments = 2\n",
        "stage2_batch_size = 4\n",
        "# Prompt file paths\n",
        "# Audio prompt options\n",
        "audio_prompt_path = \"\"\n",
        "prompt_start_time = 0.0\n",
        "prompt_end_time = 30.0\n",
        "# Dual track prompt options\n",
        "vocal_track_prompt_path = \"\"\n",
        "instrumental_track_prompt_path = \"\"\n",
        "# Output and miscellaneous options\n",
        "keep_intermediate = False\n",
        "disable_offload_model = False\n",
        "cuda_idx = 0\n",
        "seed = 42\n",
        "# Paths for xcodec and upsampler\n",
        "basic_model_config = './xcodec_mini_infer/final_ckpt/config.yaml'\n",
        "resume_path = './xcodec_mini_infer/final_ckpt/ckpt_00360000.pth'\n",
        "config_path = './xcodec_mini_infer/decoders/config.yaml'\n",
        "vocal_decoder_path = './xcodec_mini_infer/decoders/decoder_131000.pth'\n",
        "inst_decoder_path = './xcodec_mini_infer/decoders/decoder_151000.pth'\n",
        "rescale = False\n",
        "\"\"\"Main pipeline function that calls modular sub-functions for each step.\"\"\"\n",
        "\n",
        "# Validate prompt options\n",
        "print(\"Validating prompt options...\")\n",
        "validate_prompt_options(use_audio_prompt, audio_prompt_path,\n",
        "                        use_dual_tracks_prompt, vocal_track_prompt_path, instrumental_track_prompt_path)\n",
        "\n",
        "# Set up directories for outputs\n",
        "print(\"Setting up directories...\")\n",
        "stage1_output_dir, stage2_output_dir, recons_output_dir, recons_mix_dir = setup_output_directories(output_dir)\n",
        "\n",
        "# Set device and seed for reproducibility\n",
        "device = torch.device(f\"cuda:{cuda_idx}\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed_everything(seed)\n",
        "\n",
        "# Initialize tokenizer and models\n",
        "print(\"Loading models for stage 1...\")\n",
        "mmtokenizer = _MMSentencePieceTokenizer(\"./mm_tokenizer_v0.2_hf/tokenizer.model\")\n",
        "model = load_stage1_model(stage1_model, device)\n",
        "codec_model = load_codec_model(basic_model_config, resume_path, device)\n",
        "codectool = CodecManipulator(\"xcodec\", 0, 1)  # Instantiate codec helper\n",
        "\n",
        "# Read prompt files and build prompt texts\n",
        "genres, prompt_texts = read_prompt_files(genre_txt, lyrics_txt)\n",
        "\n",
        "# # Stage 1: Generate raw outputs and save npy files for vocals/instrumentals\n",
        "print(\"Performing stage 1...\")\n",
        "stage1_output_set = generate_stage1_outputs(\n",
        "    prompt_texts, genres, model, mmtokenizer, codectool, codec_model, device,\n",
        "    use_audio_prompt, audio_prompt_path, use_dual_tracks_prompt,\n",
        "    vocal_track_prompt_path, instrumental_track_prompt_path,\n",
        "    prompt_start_time, prompt_end_time, max_new_tokens,\n",
        "    top_p=0.93, temperature=1.0, repetition_penalty=1.2, stage1_output_dir=stage1_output_dir\n",
        ")\n",
        "\n",
        "# Optionally offload Stage 1 model\n",
        "if not disable_offload_model:\n",
        "    model.cpu()\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "4d0036432371409887696387e9204962",
            "41dcac0fbd0442afa20e1c88b151497a",
            "ca584de6f366497ca218119bc3b342ea",
            "dccccd6acefa43c78cddc2712ec611c9",
            "2aec58221a1b4984b11313003b00ea63",
            "3ce6c33cf19b4465b944dec9aa7ba017",
            "1b078eefbf70467aade32a9e61225ecc",
            "fadde15b49ba447aad0b2fe2cdd58e9a",
            "174da801aa4c456ba778fa541b4f0c16",
            "9c4e7f7a76b1449ebd18a808c6ecda5d",
            "25fd090831e54abbbf9a147397135456",
            "91cf649697774f7eb9c4e5b2b744b7a6",
            "2621f22c6c7345eea9aa52f46abad91a",
            "a7bf9341791543bfb75453d8d83fd044",
            "9e39ed292e2b4c299e2bef418139c210",
            "c5f743ade0b04baa95673d0e7303b94e",
            "9b83bfc1eda14a7ebf59302561357235",
            "78c5d94325cb41419b57929e16d16194",
            "ea250653b46e46d8ba0bbfd28fc97bd7",
            "88b8ed8555f64691b3a0c9a3c98bc5e0",
            "8cb2344e167b495b90ea3b627b8a28fa",
            "ee33e6d29dc947b99594de145eba3734",
            "930f8267ea02490780c43c2f2bf3c77b",
            "cd37abc09a2c4f4f8bc7343fc417925a",
            "5bc3b5a95b6f4034a283775bad8b10da",
            "753958c8bc6e42f5945271b7b241acdf",
            "749abb1fbf3649928d6a4ee3b07cc9b8",
            "55699df9d3d54513abb16aad30715624",
            "6579d46193444748b90f9d91fad9c73b",
            "d978d7dccc364f87b8719d6d104d3a21",
            "5052ebca86544454ace37cc7f4cdfb32",
            "8bee20fdb442453d8cb3069d5e67c94f",
            "660a86ac88d345f08b1a41753013d863",
            "725afe9bdb1d4395b32b389fdb52bb88",
            "76d9eaf2292248f7b665b30db6a9f284",
            "84b93924cd9242ee913f45cc6ad7e3dd",
            "cf5a09a2b571442f93ca081be3168972",
            "08a5a76e1267489daab12e9618d9ddf9",
            "1da78252aaee473ea5445e66aef3010c",
            "c0814394ce0f4727b95ef695ba9e68d3",
            "b5da230901d3459db76b603de8953851",
            "a8929690f8fc45b3834d1c878825dee1",
            "1fc092695d5747d59a00894596f80d25",
            "8e25268073c6466eb6b9683d03261748",
            "0fe3e72a6a5846adb20b4b84e3a77d1e",
            "b62409d97983469fa0a209ce59fab07b",
            "3b93e754e45c4474a83930ca427a1d51",
            "8a786bc890b94681842c837cb4dcd9ed",
            "7da954a30e0c4eb4a005e386e1a07958",
            "e05957d913394a14a593f3887a287d83",
            "7512a125f977444a9fbacdad2b6ded2f",
            "0b183303cfb84360b0ba4c57708a5707",
            "40244fd4e3a8478888ff44cc530b50e0",
            "62cbca15a6d04ee2a406c10323930479",
            "9e3714d548ef4c6ea24bec428dc95288"
          ]
        },
        "id": "JXpPzSno5vQt",
        "outputId": "079440cd-03dc-4193-da40-bd16e07246f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating prompt options...\n",
            "Setting up directories...\n",
            "Loading models for stage 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d0036432371409887696387e9204962"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91cf649697774f7eb9c4e5b2b744b7a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "930f8267ea02490780c43c2f2bf3c77b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "725afe9bdb1d4395b32b389fdb52bb88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fe3e72a6a5846adb20b4b84e3a77d1e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stage1_output_set = [stage1_output_dir+'/' + a for a in os.listdir(stage1_output_dir)]\n",
        "\n",
        "# Stage 2: Run inference on Stage 1 outputs\n",
        "print(\"Running stage 2 inferences...\")\n",
        "stage2_result = run_stage2_inference(stage2_model, stage1_output_set, stage2_output_dir, stage2_batch_size, device)\n",
        "\n",
        "# Reconstruction: Decode the Stage 2 outputs to audio tracks\n",
        "print(\"Reconstructing the track...\")\n",
        "tracks = reconstruct_tracks(stage2_result, stage1_output_dir, codec_model, device)\n",
        "\n",
        "# Mixing: Combine vocal and instrumental tracks into a mix\n",
        "print(\"Mixing the track...\")\n",
        "recons_mix = mix_tracks(tracks, recons_mix_dir)\n",
        "\n",
        "# Vocoder upsampling: Enhance audio quality using the vocoder\n",
        "print(\"Upsampling the vocoder...\")\n",
        "vocoder_mix = upsample_vocoder(stage2_result, codec_model, config_path, vocal_decoder_path, inst_decoder_path, output_dir, rescale)\n",
        "\n",
        "# Post processing: Blend low frequencies between mixes\n",
        "print(\"Post processing the audio...\")\n",
        "final_mix = post_process_audio(recons_mix, vocoder_mix, output_dir)\n",
        "\n",
        "print(\"Music pipeline completed successfully.\")\n",
        "results =  {\n",
        "    \"stage1_outputs\": stage1_output_set,\n",
        "    \"stage2_outputs\": stage2_result,\n",
        "    \"reconstructed_tracks\": tracks,\n",
        "    \"vocoder_mix\": vocoder_mix,\n",
        "    \"final_mix\": final_mix\n",
        "}\n",
        "print(\"Pipeline completed. Final mix is saved at:\", results[\"final_mix\"])"
      ],
      "metadata": {
        "id": "SAdqYYM-ORAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2oyOWpzHqhDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}